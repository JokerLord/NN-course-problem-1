{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "problem_1_starter.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4596056e4fe946958acf32b1078503ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dcb95fd547e14d66bc403193b5566eff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f14e3c292789435ba885699e7a49b71e",
              "IPY_MODEL_df1b0fe3ea08431798814338836d54c8"
            ]
          }
        },
        "dcb95fd547e14d66bc403193b5566eff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f14e3c292789435ba885699e7a49b71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e238e400ce1a44bcb499845fb65be3d7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_344152760a8d4cd68875c0cf01bfcfb4"
          }
        },
        "df1b0fe3ea08431798814338836d54c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b9cc50ec00bc4735af4e63e13660f6cc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 450/450 [01:06&lt;00:00,  6.81it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e4c86d4fb3940fca2b357e69ae6a51a"
          }
        },
        "e238e400ce1a44bcb499845fb65be3d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "344152760a8d4cd68875c0cf01bfcfb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9cc50ec00bc4735af4e63e13660f6cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e4c86d4fb3940fca2b357e69ae6a51a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8ba6557a8514d208fe6eab1ceac6cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_01dfba5e56124a2f87ebc8f2dded33d0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b23ef284767d449b8bd9b3fa1c83913e",
              "IPY_MODEL_f848f4db7e9f4a6096492cf23f81c57a"
            ]
          }
        },
        "01dfba5e56124a2f87ebc8f2dded33d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b23ef284767d449b8bd9b3fa1c83913e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3ce732b0b819458a976e4a60981c103a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4500,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6140deab71d4531aab2859dee5e6c2e"
          }
        },
        "f848f4db7e9f4a6096492cf23f81c57a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3b09b9ff41474beea73484e2716cbf21",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4500/4500 [05:41&lt;00:00, 13.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6cb8d22e649748f3b3ee6325026fc02d"
          }
        },
        "3ce732b0b819458a976e4a60981c103a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6140deab71d4531aab2859dee5e6c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b09b9ff41474beea73484e2716cbf21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6cb8d22e649748f3b3ee6325026fc02d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58278885977f48bab679510cde59dfcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_59f0e22b48dc4d9cb9aa6298f93beb42",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_990b447b4d5e4c66853a11230f717194",
              "IPY_MODEL_e76dc63cb7a4430183fce84ceaa01509"
            ]
          }
        },
        "59f0e22b48dc4d9cb9aa6298f93beb42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "990b447b4d5e4c66853a11230f717194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38391243511f46cead092f0409b8f7d7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 90,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 90,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_323aa5ddf34c4eb896d29589ca9cfd3d"
          }
        },
        "e76dc63cb7a4430183fce84ceaa01509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a11e61505c054928a3d6d3a01ff1212d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 90/90 [00:04&lt;00:00, 20.57it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbd87efada424c9aae275c3ee1ae7454"
          }
        },
        "38391243511f46cead092f0409b8f7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "323aa5ddf34c4eb896d29589ca9cfd3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a11e61505c054928a3d6d3a01ff1212d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbd87efada424c9aae275c3ee1ae7454": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atqZGIIyNSBb"
      },
      "source": [
        "#**Практическое задание №1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga5g3lUhNNBy"
      },
      "source": [
        "Установка необходимых пакетов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGBk36LpukIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d530a9-3157-4034-af9a-b58c91dc1641"
      },
      "source": [
        "!pip install -q libtiff\n",
        "!pip install -q tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▌                             | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 24.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 30kB 25.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 21.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 51kB 18.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 61kB 14.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 71kB 11.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 81kB 12.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 92kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 102kB 14.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 112kB 14.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 122kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 14.3MB/s \n",
            "\u001b[?25h  Building wheel for libtiff (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vQDLyHEO1Ux"
      },
      "source": [
        "Монтирование Вашего Google Drive к текущему окружению:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G5KkA1Nu5M9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b45ad5-7533-46c5-dc65-2dc53bb41067"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6-mtI6W1y1b"
      },
      "source": [
        "В переменную PROJECT_DIR необходимо прописать путь к директории на Google Drive, в которую Вы загрузили zip архивы с предоставленными наборами данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdvM-BUTvfSV"
      },
      "source": [
        "# todo\n",
        "PROJECT_DIR = 'NN_course/NN_prac_1_data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Num5lHV6912"
      },
      "source": [
        "Константы, которые пригодятся в коде далее:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab2yCwDm7Fqb"
      },
      "source": [
        "EVALUATE_ONLY = True\n",
        "TEST_ON_LARGE_DATASET = True\n",
        "TISSUE_CLASSES = ('ADI', 'BACK', 'DEB', 'LYM', 'MUC', 'MUS', 'NORM', 'STR', 'TUM')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgY-ux5qOI0k"
      },
      "source": [
        "Импорт необходимых зависимостей:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLHQhqiSIyvK"
      },
      "source": [
        "from pathlib import Path\n",
        "from libtiff import TIFF\n",
        "import numpy as np\n",
        "from typing import List\n",
        "from tqdm.notebook import tqdm\n",
        "from time import sleep\n",
        "from PIL import Image\n",
        "import IPython.display\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers, metrics, Input, callbacks\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKLI3lUyMYO9"
      },
      "source": [
        "---\n",
        "### Класс Dataset\n",
        "\n",
        "Предназначен для работы с наборами данных, хранящихся на Google Drive, обеспечивает чтение изображений и соответствующих меток, а также формирование пакетов (батчей)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N169efsw1ej"
      },
      "source": [
        "class Dataset:\n",
        "\n",
        "    def __init__(self, name, gdrive_dir):\n",
        "        self.name = name\n",
        "        self.is_loaded = False\n",
        "        p = Path(\"/content/drive/MyDrive/\" + gdrive_dir + name + '.npz') \n",
        "        if p.exists():\n",
        "            print(f'Loading dataset {self.name} from npz.')\n",
        "            np_obj = np.load(str(p))\n",
        "            self.images = np_obj['data']\n",
        "            self.labels = np_obj['labels']\n",
        "            self.n_files = self.images.shape[0]\n",
        "            self.is_loaded = True\n",
        "            print(f'Done. Dataset {name} consists of {self.n_files} images.')\n",
        "\n",
        "    def image(self, i):\n",
        "        # read i-th image in dataset and return it as numpy array\n",
        "        if self.is_loaded:\n",
        "            return self.images[i, :, :, :]\n",
        "\n",
        "    def images_seq(self, n=None):\n",
        "        # sequential access to images inside dataset (is needed for testing)\n",
        "        for i in range(self.n_files if not n else n):\n",
        "            yield self.image(i)\n",
        "\n",
        "    def random_image_with_label(self):\n",
        "        # get random image with label from dataset\n",
        "        i = np.random.randint(self.n_files)\n",
        "        return self.image(i), self.labels[i]\n",
        "  \n",
        "    def random_batch_with_labels(self, n):\n",
        "        # create random batch of images with labels (is needed for training)\n",
        "        indices = np.random.choice(self.n_files, n)\n",
        "        imgs = []\n",
        "        for i in indices:\n",
        "            img = self.image(i)\n",
        "            imgs.append(self.image(i))\n",
        "        logits = np.array([self.labels[i] for i in indices])\n",
        "        return np.stack(imgs), logits\n",
        "\n",
        "    def image_with_label(self, i: int):\n",
        "        # return i-th image with label from dataset\n",
        "        return self.image(i), self.labels[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaBXXCWeVLYb"
      },
      "source": [
        "---\n",
        "### Класс Metrics\n",
        "\n",
        "Реализует метрики точности, используемые для оценивания модели:\n",
        "1. точность,\n",
        "2. сбалансированную точность."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5unQ7azTinCZ"
      },
      "source": [
        "class Metrics:\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy(gt: List[int], pred: List[int]):\n",
        "        assert len(gt) == len(pred), 'gt and prediction should be of equal length'\n",
        "        return sum(int(i[0] == i[1]) for i in zip(gt, pred)) / len(gt)\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy_balanced(gt: List[int], pred: List[int]):\n",
        "        return balanced_accuracy_score(gt, pred)\n",
        "\n",
        "    @staticmethod\n",
        "    def print_all(gt: List[int], pred: List[int], info: str):\n",
        "        print(f'metrics for {info}:')\n",
        "        print('\\t accuracy {:.4f}:'.format(Metrics.accuracy(gt, pred)))\n",
        "        print('\\t balanced accuracy {:.4f}:'.format(Metrics.accuracy_balanced(gt, pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1AHzTJVGU5k"
      },
      "source": [
        "---\n",
        "### Класс Model\n",
        "\n",
        "Класс, хранящий в себе всю информацию о модели.\n",
        "\n",
        "Вам необходимо реализовать методы save, load для сохранения и заргрузки модели. Особенно актуально это будет во время тестирования на дополнительных наборах данных.\n",
        "\n",
        "> *Пожалуйста, убедитесь, что сохранение и загрузка модели работает корректно. Для этого обучите модель, протестируйте, сохраните ее в файл, перезапустите среду выполнения, загрузите обученную модель из файла, вновь протестируйте ее на тестовой выборке и убедитесь в том, что получаемые метрики совпадают с полученными для тестовой выбрки ранее.*\n",
        "\n",
        "\n",
        "Также, Вы можете реализовать дополнительные функции, такие как:\n",
        "1. валидацию модели на части обучающей выборки;\n",
        "2. использование кроссвалидации;\n",
        "3. автоматическое сохранение модели при обучении;\n",
        "4. загрузку модели с какой-то конкретной итерации обучения (если используется итеративное обучение);\n",
        "5. вывод различных показателей в процессе обучения (например, значение функции потерь на каждой эпохе);\n",
        "6. построение графиков, визуализирующих процесс обучения (например, график зависимости функции потерь от номера эпохи обучения);\n",
        "7. автоматическое тестирование на тестовом наборе/наборах данных после каждой эпохи обучения (при использовании итеративного обучения);\n",
        "8. автоматический выбор гиперпараметров модели во время обучения;\n",
        "9. сохранение и визуализацию результатов тестирования;\n",
        "10. Использование аугментации и других способов синтетического расширения набора данных (дополнительным плюсом будет обоснование необходимости и обоснование выбора конкретных типов аугментации)\n",
        "11. и т.д.\n",
        "\n",
        "Полный список опций и дополнений приведен в презентации с описанием задания.\n",
        "\n",
        "При реализации дополнительных функций допускается добавление параметров в существующие методы и добавление новых методов в класс модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pkMiB6mJ7JQ"
      },
      "source": [
        "class Model:\n",
        "\n",
        "    def __init__(self):\n",
        "        # todo\n",
        "        self.model = models.Sequential()\n",
        "        self.model.add(Input(shape=(224, 224, 3), dtype=np.float16))\n",
        "        self.model.add(layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\")) #LBL11\n",
        "        self.model.add(layers.experimental.preprocessing.RandomRotation(0.1)) #LBL11\n",
        "        self.model.add(layers.experimental.preprocessing.RandomContrast(0.15)) #LBL11\n",
        "        self.model.add(layers.Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=(224, 224, 3)))\n",
        "        self.model.add(layers.Conv2D(16, (3, 3), padding='same', activation='relu'))\n",
        "        self.model.add(layers.MaxPooling2D(2, 2))\n",
        "        self.model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "        self.model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "        self.model.add(layers.MaxPooling2D(2, 2))\n",
        "        self.model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "        self.model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "        self.model.add(layers.MaxPooling2D(2, 2))\n",
        "        self.model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "        self.model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "        self.model.add(layers.MaxPooling2D(2, 2))\n",
        "        self.model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "        self.model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "        self.model.add(layers.MaxPooling2D(2, 2)) # 7 * 7 * 256\n",
        "        self.model.add(layers.Conv2D(2048, (7, 7), activation='relu'))\n",
        "        self.model.add(layers.Dropout(0.3))\n",
        "        self.model.add(layers.Conv2D(1024, (1, 1), activation='relu'))\n",
        "        self.model.add(layers.Conv2D(256, (1, 1), activation='relu'))\n",
        "        self.model.add(layers.Dropout(0.3))\n",
        "        self.model.add(layers.Conv2D(9, (1, 1), activation='softmax'))\n",
        "        self.model.add(layers.Flatten())\n",
        "        pass\n",
        "\n",
        "    def save(self, name: str):\n",
        "        # save model to PROJECT_DIR folder on gdrive with name 'name'\n",
        "        # todo\n",
        "        p = Path(\"/content/drive/MyDrive/\" + PROJECT_DIR + name)\n",
        "        self.model.save(str(p))\n",
        "        pass\n",
        "\n",
        "    def load(self, name: str):\n",
        "        # load model with name 'name' from PROJECT_DIR folder on gdrive\n",
        "        # todo\n",
        "        p = Path(\"/content/drive/MyDrive/\" + PROJECT_DIR + name)\n",
        "        self.model = models.load_model(str(p))\n",
        "        pass\n",
        "\n",
        "    def train(self, dataset: Dataset, val_dataset: Dataset):\n",
        "        # you can add some plots for better visualization,\n",
        "        # you can add model autosaving during training,\n",
        "        # etc.\n",
        "        print(f'training started')\n",
        "        # to-do\n",
        "        opt = optimizers.Adam(learning_rate=0.00015)\n",
        "        reduce_lr = callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.3,\n",
        "            patience=1,\n",
        "            verbose=0,\n",
        "            mode='auto',\n",
        "            min_delta=0.0001,\n",
        "            cooldown=0,\n",
        "            min_lr=0\n",
        "        )\n",
        "        p = Path(\"/content/drive/MyDrive/\" + PROJECT_DIR + \"best\")\n",
        "        save_model = callbacks.ModelCheckpoint( #LBL3\n",
        "            filepath=str(p),\n",
        "            save_best_only=True,\n",
        "            save_weights_only=True,\n",
        "            monitor='val_accuracy',\n",
        "            verbose=1\n",
        "        )\n",
        "        self.model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "        history = self.model.fit(dataset.images, dataset.labels, epochs=30, validation_data = (val_dataset.images, val_dataset.labels), callbacks=[reduce_lr, save_model]) #LBL5, LBL7\n",
        "        print(f'training done')\n",
        "\n",
        "        #LBL6\n",
        "        plt.plot(history.history['accuracy'], label='accuracy')\n",
        "        plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.ylim([0.5, 1])\n",
        "        plt.legend(loc='lower right')\n",
        "        pass\n",
        "\n",
        "    def test_on_dataset(self, dataset: Dataset, limit=None):\n",
        "        # you can upgrade this code if you want to speed up testing using batches\n",
        "        predictions = []\n",
        "        n = dataset.n_files if not limit else int(dataset.n_files * limit)\n",
        "        for img in tqdm(dataset.images_seq(n), total=n):\n",
        "            predictions.append(self.test_on_image(img))\n",
        "        return predictions\n",
        "\n",
        "    def test_on_image(self, img: np.ndarray):\n",
        "        # todo: replace this code\n",
        "        prediction = np.argmax(self.model.predict(img.reshape(1, 224, 224, 3)))\n",
        "        return prediction\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMpTB6lMr00A"
      },
      "source": [
        "---\n",
        "### Классификация изображений\n",
        "\n",
        "Используя введенные выше классы можем перейти уже непосредственно к обучению модели классификации изображений. Пример общего пайплайна решения задачи приведен ниже. Вы можете его расширять и улучшать. В данном примере используются наборы данных 'train_small' и 'test_small'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cTOuZD01Up6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c748e6c-b225-470a-fb65-0de1162f4893"
      },
      "source": [
        "d_train = Dataset('train', PROJECT_DIR)\n",
        "d_test = Dataset('test', PROJECT_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset train from npz.\n",
            "Done. Dataset train consists of 18000 images.\n",
            "Loading dataset test from npz.\n",
            "Done. Dataset test consists of 4500 images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is2XIci8yetw",
        "outputId": "c18b6272-72f6-47b8-b29f-a9ac46b701f5"
      },
      "source": [
        "model = Model()\n",
        "model.model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "random_flip (RandomFlip)     (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "random_rotation (RandomRotat (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "random_contrast (RandomContr (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 224, 224, 16)      448       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 224, 224, 16)      2320      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 112, 112, 32)      4640      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 112, 112, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 56, 56, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 56, 56, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 14, 14, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 14, 14, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 1, 1, 2048)        25692160  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1, 1, 2048)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 1, 1, 1024)        2098176   \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 1, 1, 256)         262400    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 1, 1, 9)           2313      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9)                 0         \n",
            "=================================================================\n",
            "Total params: 29,233,817\n",
            "Trainable params: 29,233,817\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wBi0XpXg8_wq",
        "outputId": "d92bfc94-0a8b-4e81-e139-8665fe027846"
      },
      "source": [
        "if EVALUATE_ONLY:\n",
        "    model.train(d_train, d_test)\n",
        "    model.save('best')\n",
        "else:\n",
        "    model.load('best')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training started\n",
            "Epoch 1/30\n",
            "563/563 [==============================] - 110s 133ms/step - loss: 1.8082 - accuracy: 0.3100 - val_loss: 1.1700 - val_accuracy: 0.5793\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.57933, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 2/30\n",
            "563/563 [==============================] - 73s 130ms/step - loss: 1.0825 - accuracy: 0.5849 - val_loss: 0.7750 - val_accuracy: 0.7198\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.57933 to 0.71978, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 3/30\n",
            "563/563 [==============================] - 75s 133ms/step - loss: 0.8082 - accuracy: 0.7011 - val_loss: 0.6250 - val_accuracy: 0.7707\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71978 to 0.77067, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 4/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.5999 - accuracy: 0.7807 - val_loss: 0.4801 - val_accuracy: 0.8322\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.77067 to 0.83222, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 5/30\n",
            "563/563 [==============================] - 76s 136ms/step - loss: 0.4594 - accuracy: 0.8393 - val_loss: 0.3479 - val_accuracy: 0.8747\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.83222 to 0.87467, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 6/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.3912 - accuracy: 0.8598 - val_loss: 0.3409 - val_accuracy: 0.8778\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.87467 to 0.87778, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 7/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.3731 - accuracy: 0.8711 - val_loss: 0.5288 - val_accuracy: 0.8313\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.87778\n",
            "Epoch 8/30\n",
            "563/563 [==============================] - 76s 134ms/step - loss: 0.2484 - accuracy: 0.9147 - val_loss: 0.2203 - val_accuracy: 0.9236\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.87778 to 0.92356, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 9/30\n",
            "563/563 [==============================] - 75s 134ms/step - loss: 0.2026 - accuracy: 0.9292 - val_loss: 0.2011 - val_accuracy: 0.9296\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.92356 to 0.92956, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 10/30\n",
            "563/563 [==============================] - 75s 134ms/step - loss: 0.1907 - accuracy: 0.9358 - val_loss: 0.1740 - val_accuracy: 0.9418\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.92956 to 0.94178, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 11/30\n",
            "563/563 [==============================] - 76s 134ms/step - loss: 0.1721 - accuracy: 0.9397 - val_loss: 0.1680 - val_accuracy: 0.9467\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.94178 to 0.94667, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 12/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.1599 - accuracy: 0.9453 - val_loss: 0.1644 - val_accuracy: 0.9438\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.94667\n",
            "Epoch 13/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.1469 - accuracy: 0.9499 - val_loss: 0.1528 - val_accuracy: 0.9538\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.94667 to 0.95378, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 14/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.1472 - accuracy: 0.9500 - val_loss: 0.1429 - val_accuracy: 0.9522\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.95378\n",
            "Epoch 15/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.1496 - accuracy: 0.9501 - val_loss: 0.1290 - val_accuracy: 0.9571\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.95378 to 0.95711, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 16/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.1294 - accuracy: 0.9586 - val_loss: 0.2121 - val_accuracy: 0.9262\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.95711\n",
            "Epoch 17/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.1025 - accuracy: 0.9644 - val_loss: 0.1189 - val_accuracy: 0.9616\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.95711 to 0.96156, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 18/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.0997 - accuracy: 0.9640 - val_loss: 0.1085 - val_accuracy: 0.9691\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.96156 to 0.96911, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 19/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.0828 - accuracy: 0.9730 - val_loss: 0.1129 - val_accuracy: 0.9671\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.96911\n",
            "Epoch 20/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.0796 - accuracy: 0.9725 - val_loss: 0.1110 - val_accuracy: 0.9656\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.96911\n",
            "Epoch 21/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.0716 - accuracy: 0.9766 - val_loss: 0.1024 - val_accuracy: 0.9693\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.96911 to 0.96933, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 22/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.0708 - accuracy: 0.9754 - val_loss: 0.1078 - val_accuracy: 0.9676\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.96933\n",
            "Epoch 23/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.0694 - accuracy: 0.9770 - val_loss: 0.1026 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00023: val_accuracy improved from 0.96933 to 0.96956, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 24/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.0755 - accuracy: 0.9744 - val_loss: 0.1026 - val_accuracy: 0.9702\n",
            "\n",
            "Epoch 00024: val_accuracy improved from 0.96956 to 0.97022, saving model to /content/drive/MyDrive/NN_course/NN_prac_1_data/best\n",
            "Epoch 25/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.0669 - accuracy: 0.9763 - val_loss: 0.1023 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.97022\n",
            "Epoch 26/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.0749 - accuracy: 0.9727 - val_loss: 0.1023 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.97022\n",
            "Epoch 27/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.0674 - accuracy: 0.9778 - val_loss: 0.1023 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.97022\n",
            "Epoch 28/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.0731 - accuracy: 0.9751 - val_loss: 0.1023 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.97022\n",
            "Epoch 29/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.0735 - accuracy: 0.9739 - val_loss: 0.1023 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.97022\n",
            "Epoch 30/30\n",
            "563/563 [==============================] - 76s 135ms/step - loss: 0.0697 - accuracy: 0.9758 - val_loss: 0.1023 - val_accuracy: 0.9696\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.97022\n",
            "training done\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/NN_course/NN_prac_1_data/best/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcM2EiRMVP93"
      },
      "source": [
        "Пример тестирования модели на части набора данных:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3q9lYnA4D5y"
      },
      "source": [
        "model.load('best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0AqmeLEKqrs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "4596056e4fe946958acf32b1078503ec",
            "dcb95fd547e14d66bc403193b5566eff",
            "f14e3c292789435ba885699e7a49b71e",
            "df1b0fe3ea08431798814338836d54c8",
            "e238e400ce1a44bcb499845fb65be3d7",
            "344152760a8d4cd68875c0cf01bfcfb4",
            "b9cc50ec00bc4735af4e63e13660f6cc",
            "1e4c86d4fb3940fca2b357e69ae6a51a"
          ]
        },
        "outputId": "c33d3c00-3488-4c13-fad0-4efac0546a9a"
      },
      "source": [
        "# evaluating model on 10% of test dataset\n",
        "pred_1 = model.test_on_dataset(d_test, limit=0.1)\n",
        "Metrics.print_all(d_test.labels[:len(pred_1)], pred_1, '10% of test')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4596056e4fe946958acf32b1078503ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=450.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "metrics for 10% of test:\n",
            "\t accuracy 0.9956:\n",
            "\t balanced accuracy 0.9956:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn('y_pred contains classes not in y_true')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSwvHVVzVWZ5"
      },
      "source": [
        "Пример тестирования модели на полном наборе данных:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjI_sbMi3TMY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "c8ba6557a8514d208fe6eab1ceac6cd2",
            "01dfba5e56124a2f87ebc8f2dded33d0",
            "b23ef284767d449b8bd9b3fa1c83913e",
            "f848f4db7e9f4a6096492cf23f81c57a",
            "3ce732b0b819458a976e4a60981c103a",
            "b6140deab71d4531aab2859dee5e6c2e",
            "3b09b9ff41474beea73484e2716cbf21",
            "6cb8d22e649748f3b3ee6325026fc02d"
          ]
        },
        "outputId": "4df3a794-08cd-4dd9-bb48-c77f2955151e"
      },
      "source": [
        "# evaluating model on full test dataset (may take time)\n",
        "if TEST_ON_LARGE_DATASET:\n",
        "    pred_2 = model.test_on_dataset(d_test)\n",
        "    Metrics.print_all(d_test.labels, pred_2, 'test')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8ba6557a8514d208fe6eab1ceac6cd2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4500.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "metrics for test:\n",
            "\t accuracy 0.9696:\n",
            "\t balanced accuracy 0.9696:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvyEHdxEB18o"
      },
      "source": [
        "Результат работы пайплайна обучения и тестирования выше тоже будет оцениваться. Поэтому не забудьте присылать на проверку ноутбук с выполнеными ячейками кода с демонстрациями метрик обучения, графиками и т.п. В этом пайплайне Вам необходимо продемонстрировать работу всех реализованных дополнений, улучшений и т.п.\n",
        "\n",
        "<font color=\"red\">\n",
        "Настоятельно рекомендуется после получения пайплайна с полными результатами обучения экспортировать ноутбук в pdf (файл -> печать) и прислать этот pdf вместе с самим ноутбуком.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzSKAvVI6uCW"
      },
      "source": [
        "### Тестирование модели на других наборах данных\n",
        "\n",
        "Ваша модель должна поддерживать тестирование на других наборах данных. Для удобства, Вам предоставляется набор данных test_tiny, который представляет собой малую часть (2% изображений) набора test. Ниже приведен фрагмент кода, который будет осуществлять тестирование для оценивания Вашей модели на дополнительных тестовых наборах данных.\n",
        "\n",
        "<font color=\"red\">\n",
        "Прежде чем отсылать задание на проверку, убедитесь в работоспособности фрагмента кода ниже.\n",
        "</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ntqmd4Jzg2U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "58278885977f48bab679510cde59dfcd",
            "59f0e22b48dc4d9cb9aa6298f93beb42",
            "990b447b4d5e4c66853a11230f717194",
            "e76dc63cb7a4430183fce84ceaa01509",
            "38391243511f46cead092f0409b8f7d7",
            "323aa5ddf34c4eb896d29589ca9cfd3d",
            "a11e61505c054928a3d6d3a01ff1212d",
            "dbd87efada424c9aae275c3ee1ae7454"
          ]
        },
        "outputId": "42c2e618-c144-49d4-bf89-89512162f733"
      },
      "source": [
        "final_model = Model()\n",
        "final_model.load('best')\n",
        "d_test_tiny = Dataset('test_tiny', PROJECT_DIR)\n",
        "pred = final_model.test_on_dataset(d_test_tiny)\n",
        "Metrics.print_all(d_test_tiny.labels, pred, 'test-tiny')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset test_tiny from npz.\n",
            "Done. Dataset test_tiny consists of 90 images.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58278885977f48bab679510cde59dfcd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=90.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "metrics for test-tiny:\n",
            "\t accuracy 0.9222:\n",
            "\t balanced accuracy 0.9222:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPvyj4gscU10"
      },
      "source": [
        "Отмонтировать Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfX35zNSvFWn"
      },
      "source": [
        "drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMyDxCDCspcI"
      },
      "source": [
        "---\n",
        "# Дополнительные \"полезности\"\n",
        "\n",
        "Ниже приведены примеры использования различных функций и библиотек, которые могут быть полезны при выполнении данного практического задания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvLwSttCs1rB"
      },
      "source": [
        "### Измерение времени работы кода\n",
        "\n",
        "Измерять время работы какой-либо функции можно легко и непринужденно при помощи функции timeit из соответствующего модуля:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HnLVhwE9C9S"
      },
      "source": [
        "import timeit\n",
        "\n",
        "def factorial(n):\n",
        "    res = 1\n",
        "    for i in range(1, n + 1):\n",
        "        res *= i\n",
        "    return res\n",
        "\n",
        "\n",
        "def f():\n",
        "    return factorial(n=1000)\n",
        "\n",
        "n_runs = 128\n",
        "print(f'Function f is caluclated {n_runs} times in {timeit.timeit(f, number=n_runs)}s.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fibGVEdguOOi"
      },
      "source": [
        "### Scikit-learn\n",
        "\n",
        "Для использования \"классических\" алгоритмов машинного обучения рекомендуется использовать библиотеку scikit-learn (https://scikit-learn.org/stable/). Пример классификации изображений цифр из набора данных MNIST при помощи классификатора SVM:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXHnBzEfunAO"
      },
      "source": [
        "# Standard scientific Python imports\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import datasets, classifiers and performance metrics\n",
        "from sklearn import datasets, svm, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# The digits dataset\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# The data that we are interested in is made of 8x8 images of digits, let's\n",
        "# have a look at the first 4 images, stored in the `images` attribute of the\n",
        "# dataset.  If we were working from image files, we could load them using\n",
        "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
        "# images, we know which digit they represent: it is given in the 'target' of\n",
        "# the dataset.\n",
        "_, axes = plt.subplots(2, 4)\n",
        "images_and_labels = list(zip(digits.images, digits.target))\n",
        "for ax, (image, label) in zip(axes[0, :], images_and_labels[:4]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title('Training: %i' % label)\n",
        "\n",
        "# To apply a classifier on this data, we need to flatten the image, to\n",
        "# turn the data in a (samples, feature) matrix:\n",
        "n_samples = len(digits.images)\n",
        "data = digits.images.reshape((n_samples, -1))\n",
        "\n",
        "# Create a classifier: a support vector classifier\n",
        "classifier = svm.SVC(gamma=0.001)\n",
        "\n",
        "# Split data into train and test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, digits.target, test_size=0.5, shuffle=False)\n",
        "\n",
        "# We learn the digits on the first half of the digits\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Now predict the value of the digit on the second half:\n",
        "predicted = classifier.predict(X_test)\n",
        "\n",
        "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
        "for ax, (image, prediction) in zip(axes[1, :], images_and_predictions[:4]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    ax.set_title('Prediction: %i' % prediction)\n",
        "\n",
        "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
        "      % (classifier, metrics.classification_report(y_test, predicted)))\n",
        "disp = metrics.plot_confusion_matrix(classifier, X_test, y_test)\n",
        "disp.figure_.suptitle(\"Confusion Matrix\")\n",
        "print(\"Confusion matrix:\\n%s\" % disp.confusion_matrix)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu3Dny5zxcVy"
      },
      "source": [
        "### Scikit-image\n",
        "\n",
        "Реализовывать различные операции для работы с изображениями можно как самостоятельно, работая с массивами numpy, так и используя специализированные библиотеки, например, scikit-image (https://scikit-image.org/). Ниже приведен пример использования Canny edge detector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TZvy_d7xc0B"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "from skimage import feature\n",
        "\n",
        "\n",
        "# Generate noisy image of a square\n",
        "im = np.zeros((128, 128))\n",
        "im[32:-32, 32:-32] = 1\n",
        "\n",
        "im = ndi.rotate(im, 15, mode='constant')\n",
        "im = ndi.gaussian_filter(im, 4)\n",
        "im += 0.2 * np.random.random(im.shape)\n",
        "\n",
        "# Compute the Canny filter for two values of sigma\n",
        "edges1 = feature.canny(im)\n",
        "edges2 = feature.canny(im, sigma=3)\n",
        "\n",
        "# display results\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(8, 3),\n",
        "                                    sharex=True, sharey=True)\n",
        "\n",
        "ax1.imshow(im, cmap=plt.cm.gray)\n",
        "ax1.axis('off')\n",
        "ax1.set_title('noisy image', fontsize=20)\n",
        "\n",
        "ax2.imshow(edges1, cmap=plt.cm.gray)\n",
        "ax2.axis('off')\n",
        "ax2.set_title(r'Canny filter, $\\sigma=1$', fontsize=20)\n",
        "\n",
        "ax3.imshow(edges2, cmap=plt.cm.gray)\n",
        "ax3.axis('off')\n",
        "ax3.set_title(r'Canny filter, $\\sigma=3$', fontsize=20)\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiEWhGUQRGoH"
      },
      "source": [
        "### Tensorflow 2\n",
        "\n",
        "Для создания и обучения нейросетевых моделей можно использовать фреймворк глубокого обучения Tensorflow 2. Ниже приведен пример простейшей нейроной сети, использующейся для классификации изображений из набора данных MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDwLG7A1ReNy"
      },
      "source": [
        "# Install TensorFlow\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbvktmLwRu8g"
      },
      "source": [
        "<font color=\"red\">\n",
        "Для эффективной работы с моделями глубокого обучения убедитесь в том, что в текущей среде Google Colab используется аппаратный ускоритель GPU или TPU. Для смены среды выберите \"среда выполнения\" -> \"сменить среду выполнения\".\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJVNOOU9Sjyf"
      },
      "source": [
        "Большое количество туториалов и примеров с кодом на Tensorflow 2 можно найти на официальном сайте https://www.tensorflow.org/tutorials?hl=ru. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVPs3pYpS0U1"
      },
      "source": [
        "Также, Вам может понадобиться написать собственный генератор данных для Tensorflow 2. Скорее всего он будет достаточно простым, и его легко можно будет реализовать, используя официальную документацию TensorFlow 2. Но, на всякий случай (если не удлось сразу разобраться или хочется вникнуть в тему более глубоко), можете посмотреть следующий отличный туториал: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwI-T0IXyN84"
      },
      "source": [
        "### Numba\n",
        "\n",
        "В некоторых ситуациях, при ручных реализациях графовых алгоритмов, выполнение многократных вложенных циклов for в python можно существенно ускорить, используя JIT-компилятор Numba (https://numba.pydata.org/).\n",
        "Примеры использования Numba в Google Colab можно найти тут:\n",
        "1. https://colab.research.google.com/github/cbernet/maldives/blob/master/numba/numba_cuda.ipynb\n",
        "2. https://colab.research.google.com/github/evaneschneider/parallel-programming/blob/master/COMPASS_gpu_intro.ipynb \n",
        "\n",
        "> Пожалуйста, если Вы решили использовать Numba для решения этого практического задания, еще раз подумайте, нужно ли это Вам, и есть ли возможность реализовать требуемую функциональность иным способом. Используйте Numba только при реальной необходимости.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxAJ00A76LcF"
      },
      "source": [
        "### Работа с zip архивами в Google Drive\n",
        "\n",
        "Запаковка и распаковка zip архивов может пригодиться при сохранении и загрузки Вашей модели. Ниже приведен фрагмент кода, иллюстрирующий помещение нескольких файлов в zip архив с последующим чтением файлов из него. Все действия с директориями, файлами и архивами должны осущетвляться с примонтированным Google Drive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJiKndOpPu_e"
      },
      "source": [
        "Создадим 2 изображения, поместим их в директорию tmp внутри PROJECT_DIR, запакуем директорию tmp в архив tmp.zip."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRwgPtv-6nMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4411b2-bad0-4c36-fefe-add79ffd18c1"
      },
      "source": [
        "arr1 = np.random.rand(100, 100, 3) * 255\n",
        "arr2 = np.random.rand(100, 100, 3) * 255\n",
        "\n",
        "img1 = Image.fromarray(arr1.astype('uint8'))\n",
        "img2 = Image.fromarray(arr2.astype('uint8'))\n",
        "\n",
        "p = \"/content/drive/MyDrive/\" + PROJECT_DIR\n",
        "\n",
        "if not (Path(p) / 'tmp').exists():\n",
        "    (Path(p) / 'tmp').mkdir()\n",
        "\n",
        "img1.save(str(Path(p) / 'tmp' / 'img1.png'))\n",
        "img2.save(str(Path(p) / 'tmp' / 'img2.png'))\n",
        "\n",
        "%cd $p\n",
        "!zip -r \"tmp.zip\" \"tmp\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NN_course/NN_prac_1_data\n",
            "updating: tmp/ (stored 0%)\n",
            "updating: tmp/img1.png (stored 0%)\n",
            "updating: tmp/img2.png (stored 0%)\n",
            "test.npz\ttest_tiny.npz  tmp.zip\t  train_small.npz\n",
            "test_small.npz\ttmp\t       train.npz  train_tiny.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MykrBSWNQQlq"
      },
      "source": [
        "Распакуем архив tmp.zip в директорию tmp2 в PROJECT_DIR. Теперь внутри директории tmp2 содержится директория tmp, внутри которой находятся 2 изображения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwSWrYIWMAus"
      },
      "source": [
        "p = \"/content/drive/MyDrive/\" + PROJECT_DIR\n",
        "%cd $p\n",
        "!unzip -uq \"tmp.zip\" -d \"tmp2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HHlNQRfxwqT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}